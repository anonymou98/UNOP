#!/usr/bin/env python
import os
import sys
import argparse
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from models import UNOP
from utils import load_config
from data import GridDataset, grid_collate_fn
from torch.utils.data import DataLoader

def run_inference(args):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"  Running Inference on {device}")

    # =====================================================
    # 1. åŠ è½½é…ç½®å’Œæ¨¡å‹
    # =====================================================
    print(f"   Loading Config: {args.config}")
    config = load_config(args.config)
    
    # ä¿®æ”¹ data split ä¸º test ä»¥åŠ è½½éªŒè¯é›†
    config['data']['split'] = 'test' 

    print("  Building Model...")
    model = UNOP(config).to(device)

    print(f"  Loading Checkpoint: {args.model}")
    checkpoint = torch.load(args.model, map_location=device)
    # å¤„ç†å¯èƒ½çš„ 'model_state_dict' åŒ…è£…
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model.eval()

    # =====================================================
    # 2. å‡†å¤‡æ•°æ® (ä»éªŒè¯é›†å–ä¸€ä¸ªæ ·æœ¬)
    # =====================================================
    print("  Loading Validation Dataset...")
    try:
        dataset = GridDataset(config)
        # å–ç¬¬ 0 ä¸ªæ ·æœ¬ (ä½ å¯ä»¥ä¿®æ”¹ index å–å…¶ä»–æ ·æœ¬)
        sample_idx = 0 
        sample = dataset[sample_idx] 
        
        # GridDataset é€šå¸¸è¿”å› {'u': ...} æˆ–ç›´æ¥ Tensor
        if isinstance(sample, dict):
            # è·å–å®Œæ•´è½¨è¿¹ [T, H, W, C]
            gt_traj = sample.get('full_trajectory', sample.get('u'))
        else:
            gt_traj = sample
            
        # å¢åŠ  Batch ç»´åº¦: [T, H, W, C] -> [1, T, H, W, C]
        gt_traj = gt_traj.unsqueeze(0).to(device).float()
        
    except Exception as e:
        print(f"  æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        print("  æç¤ºï¼šè¯·æ£€æŸ¥ config ä¸­çš„ data_path æ˜¯å¦æ­£ç¡®æŒ‡å‘äº† .h5 æˆ– .npy æ–‡ä»¶")
        return

    # =====================================================
    # 3. è‡ªå›å½’æ¨ç† (Rollout)
    # =====================================================
    T_total = gt_traj.shape[1]
    steps_to_rollout = min(args.steps, T_total - 1)
    dt = config['physics']['delta_t']
    
    print(f"ğŸ”„ Running Rollout for {steps_to_rollout} steps...")
    
    # åˆå§‹æ¡ä»¶: t=0
    current = gt_traj[:, 0] # [1, H, W, C]
    spatial_size = current.shape[1:-1] # (H, W)
    
    predictions = [current]
    
    with torch.no_grad():
        for t in range(steps_to_rollout):
            # æ„é€ è¾“å…¥
            step_dt = torch.full((1,), dt, device=device)
            
            out = model({
                'current': current,
                'spatial_size': spatial_size,
                'target_time': step_dt
            })
            
            pred = out['output']
            predictions.append(pred)
            
            #   å…³é”®ï¼šæŠŠé¢„æµ‹å€¼ä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥ (Autoregressive)
            current = pred

    # æ‹¼æ¥ç»“æœ [T_pred, H, W, C] (å»æ‰ Batch ç»´åº¦)
    pred_traj = torch.cat(predictions, dim=0).cpu().numpy()
    gt_traj = gt_traj.squeeze(0).cpu().numpy()

    # =====================================================
    # 4. å¯è§†åŒ–
    # =====================================================
    print(" Plotting results...")
    plot_2d_comparison(gt_traj, pred_traj, steps_to_rollout, args.save_path)


def plot_2d_comparison(gt, pred, steps, save_path):
    """
    ç”»å›¾å‡½æ•°ï¼šå¯¹æ¯” GT, Pred, Error
    """
    # é€‰æ‹©è¦å±•ç¤ºçš„æ—¶é—´æ­¥ï¼š0, T/4, T/2, 3T/4, T
    # å‡è®¾é€šé“ 0 æ˜¯æ¶¡åº¦ (Vorticity)
    channel = 0 
    
    indices = np.linspace(0, steps, 5, dtype=int)
    
    fig, axes = plt.subplots(3, 5, figsize=(20, 10))
    
    # ç»Ÿä¸€ Colorbar èŒƒå›´
    vmin = gt[..., channel].min()
    vmax = gt[..., channel].max()
    
    cols = ['t={}'.format(i) for i in indices]
    rows = ['Ground Truth', 'Prediction', 'Abs Error']

    for i, idx in enumerate(indices):
        # 1. Ground Truth
        ax = axes[0, i]
        im1 = ax.imshow(gt[idx, ..., channel], cmap='jet', vmin=vmin, vmax=vmax, origin='lower')
        ax.set_title(f't={idx}')
        if i == 0: ax.set_ylabel(rows[0], fontsize=14, fontweight='bold')
        ax.set_xticks([]); ax.set_yticks([])

        # 2. Prediction
        ax = axes[1, i]
        im2 = ax.imshow(pred[idx, ..., channel], cmap='jet', vmin=vmin, vmax=vmax, origin='lower')
        if i == 0: ax.set_ylabel(rows[1], fontsize=14, fontweight='bold')
        ax.set_xticks([]); ax.set_yticks([])

        # 3. Error
        ax = axes[2, i]
        err = np.abs(gt[idx, ..., channel] - pred[idx, ..., channel])
        im3 = ax.imshow(err, cmap='jet', origin='lower') # Error ç”¨ä¸åŒçš„ colormap
        if i == 0: ax.set_ylabel(rows[2], fontsize=14, fontweight='bold')
        ax.set_xticks([]); ax.set_yticks([])
        
        # åœ¨æœ€åä¸€åˆ—åŠ  Colorbar
        if i == 4:
            plt.colorbar(im1, ax=axes[0, i], fraction=0.046, pad=0.04)
            plt.colorbar(im2, ax=axes[1, i], fraction=0.046, pad=0.04)
            plt.colorbar(im3, ax=axes[2, i], fraction=0.046, pad=0.04)

    plt.suptitle(f'2D Navier-Stokes Rollout Results (Steps={steps})', fontsize=16)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150)
    print(f"  Result saved to: {save_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    # é»˜è®¤ä½¿ç”¨ä½ æä¾›çš„è·¯å¾„
    parser.add_argument('--config', type=str, 
                        default='UNOP/configs/navier_stokes.yaml',
                        help='Path to config file')
    parser.add_argument('--model', type=str, 
                        default='UNOP/results/navier_stokes/model_best.pt',
                        help='Path to checkpoint')
    parser.add_argument('--steps', type=int, default=20, help='Number of rollout steps')
    parser.add_argument('--save_path', type=str, default='inference_result.png', help='Output image path')
    
    args = parser.parse_args()
    run_inference(args)